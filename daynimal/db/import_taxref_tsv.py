#!/usr/bin/env python3
"""
Import TAXREF French names from pre-processed TSV file.

This script imports French vernacular names from a TSV file that was generated
by export-taxref-tsv. The TSV uses canonical_name as key, making it compatible
with any GBIF-based database (full or minimal).

The script matches canonical_name to taxon_id from the target database, making
it work seamlessly regardless of database size or taxon_id values.

Usage:
    # Import into default database (daynimal.db)
    uv run import-taxref-tsv --file data/taxref_french_names.tsv

    # Import into specific database
    uv run import-taxref-tsv --file data/taxref_french_names.tsv --db daynimal_minimal.db

    # Dry run (preview without changes)
    uv run import-taxref-tsv --file data/taxref_french_names.tsv --dry-run

Input format:
    TSV file with 3 columns (no header):
    canonical_name    name    language

    Example:
    Panthera leo      Lion           fr
    Panthera leo      Lion d'Afrique fr

Notes:
    - canonical_name is matched against taxa.canonical_name in the database
    - Only species with rank='species' are considered for matching
    - Duplicate entries (same taxon_id + name) are automatically skipped
    - Unmatched canonical_name entries are reported but don't stop the import
    - Run 'uv run init-fts' after import to update the search index
"""

import argparse
import csv
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from daynimal.config import settings
from daynimal.db.session import get_session
from sqlalchemy import text


def import_taxref_tsv(tsv_path: Path, database_url: str | None = None, dry_run: bool = False):
    """
    Import TAXREF French names from TSV file.

    Args:
        tsv_path: Path to TSV file (generated by export-taxref-tsv)
        database_url: Optional database URL (overrides settings)
        dry_run: If True, preview without making changes
    """
    print("=" * 60)
    print("TAXREF TSV IMPORT (database-agnostic)")
    print("=" * 60)

    if not tsv_path.exists():
        print(f"[ERROR] TSV file not found: {tsv_path}")
        sys.exit(1)

    # Override database URL if provided
    original_db_url = settings.database_url
    if database_url:
        settings.database_url = database_url
        print(f"Using database: {database_url}")
    else:
        print(f"Using database: {settings.database_url}")

    if dry_run:
        print("[DRY RUN] Preview mode - no changes will be made")

    try:
        session = get_session()

        # STEP 1: Count existing French names
        print("\n[1/6] Checking existing French names...")
        existing_count = session.execute(
            text("""
                SELECT COUNT(*)
                FROM vernacular_names
                WHERE language = 'fr'
            """)
        ).scalar()
        print(f"[OK] Found {existing_count:,} existing French names")

        # STEP 2: Build canonical_name â†’ taxon_id mapping from database
        print("[2/6] Loading species from database (for canonical_name matching)...")
        canonical_to_id = {}
        result = session.execute(
            text("""
                SELECT taxon_id, canonical_name
                FROM taxa
                WHERE rank = 'species' AND canonical_name IS NOT NULL
            """)
        )
        for taxon_id, canonical in result:
            # Use lowercase for case-insensitive matching
            canonical_to_id[canonical.lower()] = taxon_id

        print(f"[OK] Loaded {len(canonical_to_id):,} species with canonical names")

        # STEP 3: Load existing names for duplicate detection
        print("[3/6] Loading existing names (for duplicate detection)...")
        existing_names = set()
        result = session.execute(
            text("""
                SELECT taxon_id, name
                FROM vernacular_names
                WHERE language = 'fr'
            """)
        )
        for taxon_id, name in result:
            existing_names.add((taxon_id, name))
        print(f"[OK] Loaded {len(existing_names):,} existing (taxon_id, name) pairs")

        # STEP 4: Parse TSV file and match canonical_name
        print(f"\n[4/6] Parsing TSV and matching canonical names: {tsv_path}")
        to_insert = []
        skipped_count = 0
        no_match_count = 0
        invalid_count = 0
        line_count = 0

        try:
            with open(tsv_path, "r", encoding="utf-8") as f:
                reader = csv.reader(f, delimiter="\t", quoting=csv.QUOTE_NONE)

                for row in reader:
                    line_count += 1

                    if len(row) != 3:
                        print(f"[WARNING] Line {line_count}: Invalid format (expected 3 columns)")
                        invalid_count += 1
                        continue

                    canonical_name = row[0].strip()
                    french_name = row[1].strip()
                    language = row[2].strip()

                    if language != "fr":
                        print(f"[WARNING] Line {line_count}: Non-French language '{language}' (skipping)")
                        invalid_count += 1
                        continue

                    if not canonical_name or not french_name:
                        print(f"[WARNING] Line {line_count}: Empty canonical_name or name")
                        invalid_count += 1
                        continue

                    # Match canonical_name to taxon_id
                    taxon_id = canonical_to_id.get(canonical_name.lower())
                    if not taxon_id:
                        no_match_count += 1
                        # Show first 10 unmatched as examples
                        if no_match_count <= 10:
                            print(f"[INFO] No match: {canonical_name} -> {french_name}")
                        continue

                    # Check for duplicates
                    if (taxon_id, french_name) in existing_names:
                        skipped_count += 1
                        continue

                    # Add to insert list
                    to_insert.append({
                        "taxon_id": taxon_id,
                        "name": french_name,
                        "language": "fr"
                    })

                    # Show first 20 as examples
                    if len(to_insert) <= 20:
                        print(f"[OK] Will add: {canonical_name} -> {french_name} (taxon_id={taxon_id})")

                    if line_count % 10000 == 0:
                        print(f"      Processed {line_count:,} lines...", end="\r")

        except Exception as e:
            print(f"[ERROR] Failed to parse TSV: {e}")
            sys.exit(1)

        print(f"\n[OK] Parsing complete:")
        print(f"      Total lines: {line_count:,}")
        print(f"      To insert: {len(to_insert):,}")
        print(f"      Skipped (duplicates): {skipped_count:,}")
        print(f"      No match: {no_match_count:,}")
        print(f"      Invalid: {invalid_count:,}")

        if not to_insert:
            print("\n[INFO] Nothing to import!")
            session.close()
            return

        # STEP 5: Bulk insert
        if not dry_run:
            print(f"\n[5/6] Bulk inserting {len(to_insert):,} names...")

            # Split into batches of 10000 for safety
            batch_size = 10000
            inserted_count = 0

            for i in range(0, len(to_insert), batch_size):
                batch = to_insert[i : i + batch_size]
                session.execute(
                    text("""
                        INSERT OR IGNORE INTO vernacular_names (taxon_id, name, language)
                        VALUES (:taxon_id, :name, :language)
                    """),
                    batch,
                )
                inserted_count += len(batch)
                print(
                    f"      Inserted batch {i // batch_size + 1}/{(len(to_insert) - 1) // batch_size + 1}"
                )

            # STEP 6: Commit
            print("[6/6] Committing changes...")
            session.commit()

            # Count final French names
            final_count = session.execute(
                text("""
                    SELECT COUNT(*)
                    FROM vernacular_names
                    WHERE language = 'fr'
                """)
            ).scalar()

            print(f"\n[SUCCESS] Import complete!")
            print(f"      French names before: {existing_count:,}")
            print(f"      French names after: {final_count:,}")
            print(f"      Added: {final_count - existing_count:,}")

            print("\n[IMPORTANT] Don't forget to rebuild the FTS5 search index:")
            print("    uv run init-fts")

        else:
            print(f"\n[DRY RUN] Would insert {len(to_insert):,} French names")
            print(f"[INFO] Would skip {skipped_count:,} (already exist)")
            print(f"[INFO] No match for {no_match_count:,} canonical names")

        session.close()

    finally:
        # Restore original database URL
        settings.database_url = original_db_url

    print("\n" + "=" * 60)
    print("IMPORT COMPLETE" if not dry_run else "DRY RUN COMPLETE")
    print("=" * 60)


def main():
    parser = argparse.ArgumentParser(
        description="Import TAXREF French names from pre-processed TSV"
    )
    parser.add_argument(
        "--file",
        type=str,
        required=True,
        help="Path to TAXREF TSV file (generated by export-taxref-tsv)",
    )
    parser.add_argument(
        "--db",
        type=str,
        help="Database file to import into (default: daynimal.db)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview without making changes",
    )

    args = parser.parse_args()

    tsv_path = Path(args.file)
    database_url = f"sqlite:///{args.db}" if args.db else None

    import_taxref_tsv(tsv_path, database_url, dry_run=args.dry_run)


if __name__ == "__main__":
    main()
